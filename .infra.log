INFO:     Started server process [2329]
INFO:     Waiting for application startup.
{"ts": "2026-02-21T23:08:12Z", "level": "WARNING", "logger": "src.api.system_factory", "msg": "M-006: Using FileBackedVectorStore (O(N) linear scan). Set USE_QDRANT=true and configure QDRANT_HOST for indexed search."}
{"ts": "2026-02-21T23:08:12Z", "level": "WARNING", "logger": "src.api.system_factory", "msg": "DRIFT-003 model catalog mismatch: selector Tier0 models missing runtime providers (6 missing). Sample: glm-4.7-flash, llama-3.1-8b-instant, llama3.1:70b, qwen2.5-coder:7b, qwen2.5:72b. Set MODEL_CATALOG_STRICT=true to fail startup."}
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]Loading weights:   1%|          | 1/103 [00:00<00:00, 2262.30it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   1%|          | 1/103 [00:00<00:00, 1602.10it/s, Materializing param=embeddings.LayerNorm.bias]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 1395.54it/s, Materializing param=embeddings.LayerNorm.weight]Loading weights:   2%|â–         | 2/103 [00:00<00:00, 862.76it/s, Materializing param=embeddings.LayerNorm.weight] Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 991.09it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 963.10it/s, Materializing param=embeddings.position_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 1233.44it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   4%|â–         | 4/103 [00:00<00:00, 1164.11it/s, Materializing param=embeddings.token_type_embeddings.weight]Loading weights:   5%|â–         | 5/103 [00:00<00:00, 1425.76it/s, Materializing param=embeddings.word_embeddings.weight]      Loading weights:   5%|â–         | 5/103 [00:00<00:00, 1412.03it/s, Materializing param=embeddings.word_embeddings.weight]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 1653.80it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 1221.23it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 1351.82it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 1257.39it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1406.95it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1383.86it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1523.91it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1478.78it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1617.55it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1607.94it/s, Materializing param=encoder.layer.0.attention.self.key.bias]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1749.61it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1739.72it/s, Materializing param=encoder.layer.0.attention.self.key.weight]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1878.19it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1868.56it/s, Materializing param=encoder.layer.0.attention.self.query.bias]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1898.67it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1861.40it/s, Materializing param=encoder.layer.0.attention.self.query.weight]Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1969.02it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1791.40it/s, Materializing param=encoder.layer.0.attention.self.value.bias]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 1814.67it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 1740.13it/s, Materializing param=encoder.layer.0.attention.self.value.weight]Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1692.02it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1678.23it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1341.09it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1225.56it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1275.04it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1269.74it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1324.66it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1318.24it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 1372.89it/s, Materializing param=encoder.layer.0.output.dense.bias]      Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 1369.48it/s, Materializing param=encoder.layer.0.output.dense.bias]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 1381.93it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 1368.52it/s, Materializing param=encoder.layer.0.output.dense.weight]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 1407.18it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 1403.40it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1259.44it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1248.16it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1291.13it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1288.52it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1332.63it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1330.21it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 1317.98it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 1294.43it/s, Materializing param=encoder.layer.1.attention.self.key.bias]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 1274.18it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 1270.05it/s, Materializing param=encoder.layer.1.attention.self.key.weight]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 1311.16it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 1308.66it/s, Materializing param=encoder.layer.1.attention.self.query.bias]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 1282.84it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 1278.66it/s, Materializing param=encoder.layer.1.attention.self.query.weight]Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 1318.78it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 1316.89it/s, Materializing param=encoder.layer.1.attention.self.value.bias]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 1357.51it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 1355.67it/s, Materializing param=encoder.layer.1.attention.self.value.weight]Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 1396.17it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 1394.33it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 1434.22it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 1432.35it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 1472.61it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 1466.59it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 1503.83it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 1501.37it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 1540.23it/s, Materializing param=encoder.layer.1.output.dense.bias]      Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 1538.13it/s, Materializing param=encoder.layer.1.output.dense.bias]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 1575.21it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 1571.79it/s, Materializing param=encoder.layer.1.output.dense.weight]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 1609.76it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 1607.43it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 1645.50it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 1643.27it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 1679.67it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 1676.93it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 1714.33it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 1710.89it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 1747.37it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 1744.82it/s, Materializing param=encoder.layer.2.attention.self.key.bias]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 1782.31it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 1779.26it/s, Materializing param=encoder.layer.2.attention.self.key.weight]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 1816.73it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 1814.43it/s, Materializing param=encoder.layer.2.attention.self.query.bias]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 1851.77it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 1849.65it/s, Materializing param=encoder.layer.2.attention.self.query.weight]Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 1887.02it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 1884.69it/s, Materializing param=encoder.layer.2.attention.self.value.bias]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 1921.74it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 1919.46it/s, Materializing param=encoder.layer.2.attention.self.value.weight]Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 1956.47it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 1954.23it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 1990.57it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 1988.23it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 2025.10it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 2022.81it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 2058.84it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 2056.53it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 2092.89it/s, Materializing param=encoder.layer.2.output.dense.bias]      Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 2090.46it/s, Materializing param=encoder.layer.2.output.dense.bias]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 2126.03it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 2123.58it/s, Materializing param=encoder.layer.2.output.dense.weight]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 2159.64it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 2157.15it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 2192.19it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 2189.68it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 2224.95it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 2222.48it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 2258.03it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 2255.53it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 2290.14it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 2287.62it/s, Materializing param=encoder.layer.3.attention.self.key.bias]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 2322.65it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 2320.10it/s, Materializing param=encoder.layer.3.attention.self.key.weight]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 2354.85it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 2352.39it/s, Materializing param=encoder.layer.3.attention.self.query.bias]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 2386.35it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 2383.64it/s, Materializing param=encoder.layer.3.attention.self.query.weight]Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 2418.16it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 2415.65it/s, Materializing param=encoder.layer.3.attention.self.value.bias]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 2450.01it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 2447.45it/s, Materializing param=encoder.layer.3.attention.self.value.weight]Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 2481.86it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 2479.27it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 2513.32it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 2510.70it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 2544.81it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 2542.17it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 2572.06it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 2567.83it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 2600.57it/s, Materializing param=encoder.layer.3.output.dense.bias]      Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 2597.49it/s, Materializing param=encoder.layer.3.output.dense.bias]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 2630.78it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 2627.84it/s, Materializing param=encoder.layer.3.output.dense.weight]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 2661.19it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 2658.16it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 2690.72it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 2687.76it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 2719.94it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 2716.96it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 2749.84it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 2746.93it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 2779.13it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 2776.22it/s, Materializing param=encoder.layer.4.attention.self.key.bias]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 2808.66it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 2805.50it/s, Materializing param=encoder.layer.4.attention.self.key.weight]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 2838.13it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 2835.17it/s, Materializing param=encoder.layer.4.attention.self.query.bias]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 2867.45it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 2864.68it/s, Materializing param=encoder.layer.4.attention.self.query.weight]Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 2896.70it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 2893.83it/s, Materializing param=encoder.layer.4.attention.self.value.bias]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 2925.91it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 2922.89it/s, Materializing param=encoder.layer.4.attention.self.value.weight]Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 2954.85it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 2951.81it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 2983.85it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 2980.90it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 2987.92it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 2956.22it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 2951.31it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 2927.26it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 2934.79it/s, Materializing param=encoder.layer.4.output.dense.bias]      Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 2896.24it/s, Materializing param=encoder.layer.4.output.dense.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 2896.78it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 2891.36it/s, Materializing param=encoder.layer.4.output.dense.weight]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 2915.63it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 2912.38it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 2932.54it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 2922.60it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 2946.50it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 2942.93it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 2970.02it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 2966.86it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 2994.79it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 2991.71it/s, Materializing param=encoder.layer.5.attention.self.key.bias]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 3019.73it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 3016.63it/s, Materializing param=encoder.layer.5.attention.self.key.weight]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 3044.75it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 3041.91it/s, Materializing param=encoder.layer.5.attention.self.query.bias]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 3070.02it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 3067.17it/s, Materializing param=encoder.layer.5.attention.self.query.weight]Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 3095.16it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 3088.32it/s, Materializing param=encoder.layer.5.attention.self.value.bias]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 3103.04it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 3097.69it/s, Materializing param=encoder.layer.5.attention.self.value.weight]Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 3123.26it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 3120.01it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 3143.72it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 3136.93it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 3159.84it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 3156.78it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 3183.47it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 3179.38it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 3206.58it/s, Materializing param=encoder.layer.5.output.dense.bias]     Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 3203.57it/s, Materializing param=encoder.layer.5.output.dense.bias]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 3230.35it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 3227.47it/s, Materializing param=encoder.layer.5.output.dense.weight]Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 3254.61it/s, Materializing param=pooler.dense.bias]                  Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 3251.79it/s, Materializing param=pooler.dense.bias]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 3279.01it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 3276.18it/s, Materializing param=pooler.dense.weight]Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 3267.88it/s, Materializing param=pooler.dense.weight]
[1mBertModel LOAD REPORT[0m from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

[3mNotes:
- UNEXPECTED[3m	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.[0m
{"ts": "2026-02-21T23:08:19Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"analyze_query\", \"correlation_id\": \"bd1a2cf45de6\", \"duration_ms\": 15.02, \"confidence\": 0.0, \"tier\": null, \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:19Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"confidence\", \"correlation_id\": \"bd1a2cf45de6\", \"duration_ms\": 0.22, \"confidence\": 68.43, \"tier\": null, \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:19Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"mode_decision\", \"correlation_id\": \"bd1a2cf45de6\", \"duration_ms\": 0.0, \"confidence\": 68.43, \"tier\": null, \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:19Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"model_selection\", \"correlation_id\": \"bd1a2cf45de6\", \"duration_ms\": 0.18, \"confidence\": 68.43, \"tier\": \"tier0\", \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"provider_call\", \"correlation_id\": \"bd1a2cf45de6\", \"duration_ms\": 440.15, \"confidence\": 68.43, \"tier\": \"tier0\", \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"response_packaging\", \"correlation_id\": \"bd1a2cf45de6\", \"duration_ms\": 0.04, \"confidence\": 68.43, \"tier\": \"tier0\", \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.decisions", "msg": "{'event': 'router_decision', 'correlation_id': 'bd1a2cf45de6', 'trace_id': 'bd1a2cf45de6', 'profile': 'auto', 'routing_tier': 'SIMPLE', 'provider_decision': {'mode': 'direct', 'provider': 'groq', 'model': 'llama-3.3-70b-versatile', 'tier': 'tier0'}, 'tier_used': 'tier0', 'model_used': 'llama-3.3-70b-versatile', 'confidence': 68.43, 'estimated_cost': 0.0, 'latency_ms': 457.07, 'cost_estimate': 0.0, 'estimated_savings': 0.08249999999999999, 'wallet_charge_usdc': None}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"analyze_query\", \"correlation_id\": \"8c3b692cc795\", \"duration_ms\": 11.45, \"confidence\": 0.0, \"tier\": null, \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"confidence\", \"correlation_id\": \"8c3b692cc795\", \"duration_ms\": 0.06, \"confidence\": 78.39, \"tier\": null, \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"mode_decision\", \"correlation_id\": \"8c3b692cc795\", \"duration_ms\": 0.0, \"confidence\": 78.39, \"tier\": null, \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"model_selection\", \"correlation_id\": \"8c3b692cc795\", \"duration_ms\": 0.04, \"confidence\": 78.39, \"tier\": \"tier0\", \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"provider_call\", \"correlation_id\": \"8c3b692cc795\", \"duration_ms\": 58.32, \"confidence\": 0.0, \"tier\": \"tier0\", \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.beads", "msg": "{\"event\": \"router_bead_completed\", \"bead\": \"response_packaging\", \"correlation_id\": \"8c3b692cc795\", \"duration_ms\": 0.02, \"confidence\": 0.0, \"tier\": \"tier0\", \"cost_estimate\": 0.0, \"success\": true}"}
{"ts": "2026-02-21T23:08:20Z", "level": "INFO", "logger": "router.decisions", "msg": "{'event': 'router_decision', 'correlation_id': '8c3b692cc795', 'trace_id': '8c3b692cc795', 'profile': 'venice-only', 'routing_tier': 'SIMPLE', 'provider_decision': {'mode': 'direct', 'provider': 'venice', 'model': 'zai-org-glm-4.7-flash', 'tier': 'tier0'}, 'tier_used': 'tier0', 'model_used': 'zai-org-glm-4.7-flash', 'confidence': 0.0, 'estimated_cost': 0.0, 'latency_ms': 70.424, 'cost_estimate': 0.0, 'estimated_savings': 0.08249999999999999, 'wallet_charge_usdc': None}"}
